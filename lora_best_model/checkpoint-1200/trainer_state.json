{
  "best_global_step": 1200,
  "best_metric": 0.009143976494669914,
  "best_model_checkpoint": "lora_model/checkpoint-1200",
  "epoch": 2.0726172465960664,
  "eval_steps": 100,
  "global_step": 1200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017289820618111088,
      "grad_norm": 2.42889666557312,
      "learning_rate": 9.94818652849741e-05,
      "loss": 2.7068,
      "step": 10
    },
    {
      "epoch": 0.034579641236222175,
      "grad_norm": 1.740929365158081,
      "learning_rate": 9.890616004605642e-05,
      "loss": 1.148,
      "step": 20
    },
    {
      "epoch": 0.05186946185433326,
      "grad_norm": 1.0443369150161743,
      "learning_rate": 9.833045480713876e-05,
      "loss": 0.2946,
      "step": 30
    },
    {
      "epoch": 0.06915928247244435,
      "grad_norm": 0.7644584774971008,
      "learning_rate": 9.775474956822108e-05,
      "loss": 0.081,
      "step": 40
    },
    {
      "epoch": 0.08644910309055544,
      "grad_norm": 1.5424360036849976,
      "learning_rate": 9.71790443293034e-05,
      "loss": 0.0454,
      "step": 50
    },
    {
      "epoch": 0.10373892370866653,
      "grad_norm": 1.6630324125289917,
      "learning_rate": 9.660333909038573e-05,
      "loss": 0.0458,
      "step": 60
    },
    {
      "epoch": 0.12102874432677761,
      "grad_norm": 1.0464941263198853,
      "learning_rate": 9.602763385146805e-05,
      "loss": 0.0267,
      "step": 70
    },
    {
      "epoch": 0.1383185649448887,
      "grad_norm": 1.754212737083435,
      "learning_rate": 9.545192861255039e-05,
      "loss": 0.0225,
      "step": 80
    },
    {
      "epoch": 0.15560838556299977,
      "grad_norm": 0.07106610387563705,
      "learning_rate": 9.48762233736327e-05,
      "loss": 0.0122,
      "step": 90
    },
    {
      "epoch": 0.17289820618111088,
      "grad_norm": 0.9235786199569702,
      "learning_rate": 9.430051813471503e-05,
      "loss": 0.018,
      "step": 100
    },
    {
      "epoch": 0.17289820618111088,
      "eval_loss": 0.04397467523813248,
      "eval_runtime": 220.7371,
      "eval_samples_per_second": 14.125,
      "eval_steps_per_second": 1.767,
      "step": 100
    },
    {
      "epoch": 0.19018802679922195,
      "grad_norm": 0.6752650737762451,
      "learning_rate": 9.372481289579736e-05,
      "loss": 0.0351,
      "step": 110
    },
    {
      "epoch": 0.20747784741733305,
      "grad_norm": 0.40194863080978394,
      "learning_rate": 9.314910765687968e-05,
      "loss": 0.0116,
      "step": 120
    },
    {
      "epoch": 0.22476766803544412,
      "grad_norm": 0.548344612121582,
      "learning_rate": 9.257340241796201e-05,
      "loss": 0.0209,
      "step": 130
    },
    {
      "epoch": 0.24205748865355523,
      "grad_norm": 0.7498963475227356,
      "learning_rate": 9.199769717904433e-05,
      "loss": 0.0182,
      "step": 140
    },
    {
      "epoch": 0.2593473092716663,
      "grad_norm": 0.514229953289032,
      "learning_rate": 9.142199194012667e-05,
      "loss": 0.0146,
      "step": 150
    },
    {
      "epoch": 0.2766371298897774,
      "grad_norm": 0.5074368715286255,
      "learning_rate": 9.084628670120899e-05,
      "loss": 0.0233,
      "step": 160
    },
    {
      "epoch": 0.2939269505078885,
      "grad_norm": 0.3097727596759796,
      "learning_rate": 9.027058146229131e-05,
      "loss": 0.0153,
      "step": 170
    },
    {
      "epoch": 0.31121677112599955,
      "grad_norm": 0.5345416069030762,
      "learning_rate": 8.969487622337364e-05,
      "loss": 0.0204,
      "step": 180
    },
    {
      "epoch": 0.3285065917441107,
      "grad_norm": 0.8955140709877014,
      "learning_rate": 8.911917098445596e-05,
      "loss": 0.0226,
      "step": 190
    },
    {
      "epoch": 0.34579641236222175,
      "grad_norm": 0.9952807426452637,
      "learning_rate": 8.85434657455383e-05,
      "loss": 0.019,
      "step": 200
    },
    {
      "epoch": 0.34579641236222175,
      "eval_loss": 0.027776462957262993,
      "eval_runtime": 246.9915,
      "eval_samples_per_second": 12.624,
      "eval_steps_per_second": 1.579,
      "step": 200
    },
    {
      "epoch": 0.3630862329803328,
      "grad_norm": 0.21740400791168213,
      "learning_rate": 8.796776050662062e-05,
      "loss": 0.0083,
      "step": 210
    },
    {
      "epoch": 0.3803760535984439,
      "grad_norm": 0.5773666501045227,
      "learning_rate": 8.739205526770295e-05,
      "loss": 0.0107,
      "step": 220
    },
    {
      "epoch": 0.397665874216555,
      "grad_norm": 0.6944692730903625,
      "learning_rate": 8.681635002878527e-05,
      "loss": 0.0218,
      "step": 230
    },
    {
      "epoch": 0.4149556948346661,
      "grad_norm": 0.6007096171379089,
      "learning_rate": 8.624064478986759e-05,
      "loss": 0.0113,
      "step": 240
    },
    {
      "epoch": 0.4322455154527772,
      "grad_norm": 0.642648458480835,
      "learning_rate": 8.566493955094992e-05,
      "loss": 0.0117,
      "step": 250
    },
    {
      "epoch": 0.44953533607088825,
      "grad_norm": 0.3415372371673584,
      "learning_rate": 8.508923431203224e-05,
      "loss": 0.017,
      "step": 260
    },
    {
      "epoch": 0.4668251566889994,
      "grad_norm": 0.20580579340457916,
      "learning_rate": 8.451352907311458e-05,
      "loss": 0.018,
      "step": 270
    },
    {
      "epoch": 0.48411497730711045,
      "grad_norm": 0.09950713813304901,
      "learning_rate": 8.39378238341969e-05,
      "loss": 0.0089,
      "step": 280
    },
    {
      "epoch": 0.5014047979252215,
      "grad_norm": 0.018063344061374664,
      "learning_rate": 8.336211859527923e-05,
      "loss": 0.0085,
      "step": 290
    },
    {
      "epoch": 0.5186946185433327,
      "grad_norm": 0.3869982063770294,
      "learning_rate": 8.278641335636155e-05,
      "loss": 0.008,
      "step": 300
    },
    {
      "epoch": 0.5186946185433327,
      "eval_loss": 0.02418840490281582,
      "eval_runtime": 230.2161,
      "eval_samples_per_second": 13.544,
      "eval_steps_per_second": 1.694,
      "step": 300
    },
    {
      "epoch": 0.5359844391614437,
      "grad_norm": 0.1594521403312683,
      "learning_rate": 8.221070811744387e-05,
      "loss": 0.0163,
      "step": 310
    },
    {
      "epoch": 0.5532742597795548,
      "grad_norm": 0.0240822434425354,
      "learning_rate": 8.163500287852621e-05,
      "loss": 0.0142,
      "step": 320
    },
    {
      "epoch": 0.5705640803976659,
      "grad_norm": 0.04584798589348793,
      "learning_rate": 8.105929763960853e-05,
      "loss": 0.0104,
      "step": 330
    },
    {
      "epoch": 0.587853901015777,
      "grad_norm": 0.08252394199371338,
      "learning_rate": 8.048359240069086e-05,
      "loss": 0.0149,
      "step": 340
    },
    {
      "epoch": 0.6051437216338881,
      "grad_norm": 1.388727068901062,
      "learning_rate": 7.990788716177318e-05,
      "loss": 0.0153,
      "step": 350
    },
    {
      "epoch": 0.6224335422519991,
      "grad_norm": 0.03460799902677536,
      "learning_rate": 7.93321819228555e-05,
      "loss": 0.0142,
      "step": 360
    },
    {
      "epoch": 0.6397233628701102,
      "grad_norm": 1.0219424962997437,
      "learning_rate": 7.875647668393784e-05,
      "loss": 0.0141,
      "step": 370
    },
    {
      "epoch": 0.6570131834882214,
      "grad_norm": 0.09818519651889801,
      "learning_rate": 7.818077144502016e-05,
      "loss": 0.0179,
      "step": 380
    },
    {
      "epoch": 0.6743030041063324,
      "grad_norm": 0.4170227348804474,
      "learning_rate": 7.760506620610249e-05,
      "loss": 0.0247,
      "step": 390
    },
    {
      "epoch": 0.6915928247244435,
      "grad_norm": 0.5482088923454285,
      "learning_rate": 7.702936096718481e-05,
      "loss": 0.0099,
      "step": 400
    },
    {
      "epoch": 0.6915928247244435,
      "eval_loss": 0.014767882414162159,
      "eval_runtime": 232.5499,
      "eval_samples_per_second": 13.408,
      "eval_steps_per_second": 1.677,
      "step": 400
    },
    {
      "epoch": 0.7088826453425545,
      "grad_norm": 0.07137695699930191,
      "learning_rate": 7.645365572826713e-05,
      "loss": 0.0152,
      "step": 410
    },
    {
      "epoch": 0.7261724659606656,
      "grad_norm": 0.33588138222694397,
      "learning_rate": 7.587795048934946e-05,
      "loss": 0.012,
      "step": 420
    },
    {
      "epoch": 0.7434622865787768,
      "grad_norm": 0.27086585760116577,
      "learning_rate": 7.530224525043178e-05,
      "loss": 0.0126,
      "step": 430
    },
    {
      "epoch": 0.7607521071968878,
      "grad_norm": 0.07182415574789047,
      "learning_rate": 7.472654001151412e-05,
      "loss": 0.0101,
      "step": 440
    },
    {
      "epoch": 0.7780419278149989,
      "grad_norm": 0.07890437543392181,
      "learning_rate": 7.415083477259644e-05,
      "loss": 0.0065,
      "step": 450
    },
    {
      "epoch": 0.79533174843311,
      "grad_norm": 0.008411087095737457,
      "learning_rate": 7.357512953367876e-05,
      "loss": 0.0018,
      "step": 460
    },
    {
      "epoch": 0.8126215690512211,
      "grad_norm": 0.014768620952963829,
      "learning_rate": 7.299942429476109e-05,
      "loss": 0.008,
      "step": 470
    },
    {
      "epoch": 0.8299113896693322,
      "grad_norm": 0.7333629727363586,
      "learning_rate": 7.242371905584341e-05,
      "loss": 0.005,
      "step": 480
    },
    {
      "epoch": 0.8472012102874432,
      "grad_norm": 0.0056016817688941956,
      "learning_rate": 7.184801381692575e-05,
      "loss": 0.0052,
      "step": 490
    },
    {
      "epoch": 0.8644910309055543,
      "grad_norm": 0.08357653021812439,
      "learning_rate": 7.127230857800807e-05,
      "loss": 0.0074,
      "step": 500
    },
    {
      "epoch": 0.8644910309055543,
      "eval_loss": 0.01476307399570942,
      "eval_runtime": 266.5524,
      "eval_samples_per_second": 11.698,
      "eval_steps_per_second": 1.463,
      "step": 500
    },
    {
      "epoch": 0.8817808515236655,
      "grad_norm": 0.008205403573811054,
      "learning_rate": 7.069660333909039e-05,
      "loss": 0.0103,
      "step": 510
    },
    {
      "epoch": 0.8990706721417765,
      "grad_norm": 0.2517716884613037,
      "learning_rate": 7.012089810017272e-05,
      "loss": 0.0132,
      "step": 520
    },
    {
      "epoch": 0.9163604927598876,
      "grad_norm": 0.05394650250673294,
      "learning_rate": 6.954519286125504e-05,
      "loss": 0.0069,
      "step": 530
    },
    {
      "epoch": 0.9336503133779988,
      "grad_norm": 0.46381035447120667,
      "learning_rate": 6.896948762233738e-05,
      "loss": 0.0171,
      "step": 540
    },
    {
      "epoch": 0.9509401339961098,
      "grad_norm": 0.07970879226922989,
      "learning_rate": 6.83937823834197e-05,
      "loss": 0.0105,
      "step": 550
    },
    {
      "epoch": 0.9682299546142209,
      "grad_norm": 0.033524058759212494,
      "learning_rate": 6.781807714450203e-05,
      "loss": 0.0135,
      "step": 560
    },
    {
      "epoch": 0.9855197752323319,
      "grad_norm": 0.014198850840330124,
      "learning_rate": 6.724237190558435e-05,
      "loss": 0.011,
      "step": 570
    },
    {
      "epoch": 1.0017289820618112,
      "grad_norm": 0.01398998498916626,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.0126,
      "step": 580
    },
    {
      "epoch": 1.0190188026799223,
      "grad_norm": 0.0595741905272007,
      "learning_rate": 6.6090961427749e-05,
      "loss": 0.0052,
      "step": 590
    },
    {
      "epoch": 1.0363086232980332,
      "grad_norm": 0.09921371936798096,
      "learning_rate": 6.551525618883132e-05,
      "loss": 0.0026,
      "step": 600
    },
    {
      "epoch": 1.0363086232980332,
      "eval_loss": 0.012546573765575886,
      "eval_runtime": 236.1335,
      "eval_samples_per_second": 13.204,
      "eval_steps_per_second": 1.652,
      "step": 600
    },
    {
      "epoch": 1.0535984439161443,
      "grad_norm": 0.719194233417511,
      "learning_rate": 6.493955094991366e-05,
      "loss": 0.0094,
      "step": 610
    },
    {
      "epoch": 1.0708882645342555,
      "grad_norm": 0.04661912843585014,
      "learning_rate": 6.436384571099598e-05,
      "loss": 0.0028,
      "step": 620
    },
    {
      "epoch": 1.0881780851523666,
      "grad_norm": 0.010387794114649296,
      "learning_rate": 6.37881404720783e-05,
      "loss": 0.0082,
      "step": 630
    },
    {
      "epoch": 1.1054679057704777,
      "grad_norm": 0.7159293293952942,
      "learning_rate": 6.321243523316063e-05,
      "loss": 0.0032,
      "step": 640
    },
    {
      "epoch": 1.1227577263885886,
      "grad_norm": 0.3750959038734436,
      "learning_rate": 6.263672999424295e-05,
      "loss": 0.0105,
      "step": 650
    },
    {
      "epoch": 1.1400475470066997,
      "grad_norm": 0.029124077409505844,
      "learning_rate": 6.206102475532529e-05,
      "loss": 0.013,
      "step": 660
    },
    {
      "epoch": 1.1573373676248109,
      "grad_norm": 0.4249098002910614,
      "learning_rate": 6.14853195164076e-05,
      "loss": 0.009,
      "step": 670
    },
    {
      "epoch": 1.174627188242922,
      "grad_norm": 0.01096789725124836,
      "learning_rate": 6.090961427748993e-05,
      "loss": 0.0065,
      "step": 680
    },
    {
      "epoch": 1.1919170088610331,
      "grad_norm": 0.016583872959017754,
      "learning_rate": 6.0333909038572254e-05,
      "loss": 0.0064,
      "step": 690
    },
    {
      "epoch": 1.209206829479144,
      "grad_norm": 0.20748314261436462,
      "learning_rate": 5.9758203799654574e-05,
      "loss": 0.0118,
      "step": 700
    },
    {
      "epoch": 1.209206829479144,
      "eval_loss": 0.014963719993829727,
      "eval_runtime": 229.0678,
      "eval_samples_per_second": 13.612,
      "eval_steps_per_second": 1.703,
      "step": 700
    },
    {
      "epoch": 1.2264966500972552,
      "grad_norm": 0.3983844220638275,
      "learning_rate": 5.918249856073691e-05,
      "loss": 0.0124,
      "step": 710
    },
    {
      "epoch": 1.2437864707153663,
      "grad_norm": 0.09338133782148361,
      "learning_rate": 5.860679332181923e-05,
      "loss": 0.0084,
      "step": 720
    },
    {
      "epoch": 1.2610762913334774,
      "grad_norm": 0.04088938981294632,
      "learning_rate": 5.8031088082901555e-05,
      "loss": 0.0068,
      "step": 730
    },
    {
      "epoch": 1.2783661119515886,
      "grad_norm": 0.08590110391378403,
      "learning_rate": 5.745538284398388e-05,
      "loss": 0.0068,
      "step": 740
    },
    {
      "epoch": 1.2956559325696997,
      "grad_norm": 0.026872120797634125,
      "learning_rate": 5.687967760506621e-05,
      "loss": 0.0034,
      "step": 750
    },
    {
      "epoch": 1.3129457531878106,
      "grad_norm": 0.018410684540867805,
      "learning_rate": 5.6303972366148536e-05,
      "loss": 0.0036,
      "step": 760
    },
    {
      "epoch": 1.3302355738059217,
      "grad_norm": 0.008157606236636639,
      "learning_rate": 5.572826712723086e-05,
      "loss": 0.0013,
      "step": 770
    },
    {
      "epoch": 1.3475253944240329,
      "grad_norm": 0.14661750197410583,
      "learning_rate": 5.5152561888313184e-05,
      "loss": 0.0096,
      "step": 780
    },
    {
      "epoch": 1.364815215042144,
      "grad_norm": 0.09605702012777328,
      "learning_rate": 5.457685664939551e-05,
      "loss": 0.0056,
      "step": 790
    },
    {
      "epoch": 1.3821050356602549,
      "grad_norm": 0.01941852830350399,
      "learning_rate": 5.400115141047784e-05,
      "loss": 0.0039,
      "step": 800
    },
    {
      "epoch": 1.3821050356602549,
      "eval_loss": 0.014056062325835228,
      "eval_runtime": 258.1591,
      "eval_samples_per_second": 12.078,
      "eval_steps_per_second": 1.511,
      "step": 800
    },
    {
      "epoch": 1.399394856278366,
      "grad_norm": 0.40836450457572937,
      "learning_rate": 5.3425446171560165e-05,
      "loss": 0.0053,
      "step": 810
    },
    {
      "epoch": 1.4166846768964771,
      "grad_norm": 0.43449288606643677,
      "learning_rate": 5.284974093264249e-05,
      "loss": 0.0029,
      "step": 820
    },
    {
      "epoch": 1.4339744975145883,
      "grad_norm": 0.24794958531856537,
      "learning_rate": 5.227403569372481e-05,
      "loss": 0.0061,
      "step": 830
    },
    {
      "epoch": 1.4512643181326994,
      "grad_norm": 0.23647944629192352,
      "learning_rate": 5.169833045480714e-05,
      "loss": 0.0059,
      "step": 840
    },
    {
      "epoch": 1.4685541387508105,
      "grad_norm": 0.4763752222061157,
      "learning_rate": 5.1122625215889466e-05,
      "loss": 0.0048,
      "step": 850
    },
    {
      "epoch": 1.4858439593689217,
      "grad_norm": 0.007770438212901354,
      "learning_rate": 5.0546919976971793e-05,
      "loss": 0.0056,
      "step": 860
    },
    {
      "epoch": 1.5031337799870328,
      "grad_norm": 0.4555712044239044,
      "learning_rate": 4.997121473805412e-05,
      "loss": 0.0061,
      "step": 870
    },
    {
      "epoch": 1.5204236006051437,
      "grad_norm": 0.18479640781879425,
      "learning_rate": 4.939550949913645e-05,
      "loss": 0.0054,
      "step": 880
    },
    {
      "epoch": 1.5377134212232548,
      "grad_norm": 0.06064339727163315,
      "learning_rate": 4.881980426021877e-05,
      "loss": 0.0056,
      "step": 890
    },
    {
      "epoch": 1.5550032418413657,
      "grad_norm": 0.32364413142204285,
      "learning_rate": 4.8244099021301095e-05,
      "loss": 0.0044,
      "step": 900
    },
    {
      "epoch": 1.5550032418413657,
      "eval_loss": 0.012953612953424454,
      "eval_runtime": 229.6299,
      "eval_samples_per_second": 13.578,
      "eval_steps_per_second": 1.698,
      "step": 900
    },
    {
      "epoch": 1.5722930624594769,
      "grad_norm": 0.030104056000709534,
      "learning_rate": 4.766839378238342e-05,
      "loss": 0.0059,
      "step": 910
    },
    {
      "epoch": 1.589582883077588,
      "grad_norm": 0.06166328117251396,
      "learning_rate": 4.709268854346575e-05,
      "loss": 0.004,
      "step": 920
    },
    {
      "epoch": 1.6068727036956991,
      "grad_norm": 0.5038527250289917,
      "learning_rate": 4.6516983304548076e-05,
      "loss": 0.0065,
      "step": 930
    },
    {
      "epoch": 1.6241625243138103,
      "grad_norm": 0.0074651604518294334,
      "learning_rate": 4.59412780656304e-05,
      "loss": 0.0068,
      "step": 940
    },
    {
      "epoch": 1.6414523449319214,
      "grad_norm": 0.010953253135085106,
      "learning_rate": 4.536557282671273e-05,
      "loss": 0.0097,
      "step": 950
    },
    {
      "epoch": 1.6587421655500325,
      "grad_norm": 0.0865335464477539,
      "learning_rate": 4.478986758779505e-05,
      "loss": 0.0056,
      "step": 960
    },
    {
      "epoch": 1.6760319861681436,
      "grad_norm": 0.36973193287849426,
      "learning_rate": 4.421416234887738e-05,
      "loss": 0.0094,
      "step": 970
    },
    {
      "epoch": 1.6933218067862545,
      "grad_norm": 0.005710284225642681,
      "learning_rate": 4.3638457109959704e-05,
      "loss": 0.0039,
      "step": 980
    },
    {
      "epoch": 1.7106116274043657,
      "grad_norm": 0.004267771728336811,
      "learning_rate": 4.306275187104203e-05,
      "loss": 0.0032,
      "step": 990
    },
    {
      "epoch": 1.7279014480224768,
      "grad_norm": 0.007419025059789419,
      "learning_rate": 4.248704663212436e-05,
      "loss": 0.0014,
      "step": 1000
    },
    {
      "epoch": 1.7279014480224768,
      "eval_loss": 0.011084304191172123,
      "eval_runtime": 236.9398,
      "eval_samples_per_second": 13.159,
      "eval_steps_per_second": 1.646,
      "step": 1000
    },
    {
      "epoch": 1.7451912686405877,
      "grad_norm": 0.003762888489291072,
      "learning_rate": 4.1911341393206686e-05,
      "loss": 0.0061,
      "step": 1010
    },
    {
      "epoch": 1.7624810892586988,
      "grad_norm": 0.007091403007507324,
      "learning_rate": 4.1335636154289006e-05,
      "loss": 0.0067,
      "step": 1020
    },
    {
      "epoch": 1.77977090987681,
      "grad_norm": 0.0872105062007904,
      "learning_rate": 4.075993091537133e-05,
      "loss": 0.0051,
      "step": 1030
    },
    {
      "epoch": 1.797060730494921,
      "grad_norm": 0.018922526389360428,
      "learning_rate": 4.018422567645366e-05,
      "loss": 0.0049,
      "step": 1040
    },
    {
      "epoch": 1.8143505511130322,
      "grad_norm": 0.49124178290367126,
      "learning_rate": 3.960852043753599e-05,
      "loss": 0.0039,
      "step": 1050
    },
    {
      "epoch": 1.8316403717311434,
      "grad_norm": 0.27416500449180603,
      "learning_rate": 3.9032815198618314e-05,
      "loss": 0.0056,
      "step": 1060
    },
    {
      "epoch": 1.8489301923492545,
      "grad_norm": 0.004407179541885853,
      "learning_rate": 3.8457109959700634e-05,
      "loss": 0.0066,
      "step": 1070
    },
    {
      "epoch": 1.8662200129673656,
      "grad_norm": 0.022854749113321304,
      "learning_rate": 3.788140472078296e-05,
      "loss": 0.0099,
      "step": 1080
    },
    {
      "epoch": 1.8835098335854765,
      "grad_norm": 0.0858723372220993,
      "learning_rate": 3.730569948186529e-05,
      "loss": 0.0047,
      "step": 1090
    },
    {
      "epoch": 1.9007996542035877,
      "grad_norm": 0.012378251180052757,
      "learning_rate": 3.6729994242947615e-05,
      "loss": 0.0016,
      "step": 1100
    },
    {
      "epoch": 1.9007996542035877,
      "eval_loss": 0.011301898397505283,
      "eval_runtime": 232.0541,
      "eval_samples_per_second": 13.437,
      "eval_steps_per_second": 1.681,
      "step": 1100
    },
    {
      "epoch": 1.9180894748216986,
      "grad_norm": 0.030595634132623672,
      "learning_rate": 3.615428900402994e-05,
      "loss": 0.0043,
      "step": 1110
    },
    {
      "epoch": 1.9353792954398097,
      "grad_norm": 0.26082995533943176,
      "learning_rate": 3.557858376511227e-05,
      "loss": 0.0018,
      "step": 1120
    },
    {
      "epoch": 1.9526691160579208,
      "grad_norm": 0.004988342057913542,
      "learning_rate": 3.500287852619459e-05,
      "loss": 0.0122,
      "step": 1130
    },
    {
      "epoch": 1.969958936676032,
      "grad_norm": 0.009113270789384842,
      "learning_rate": 3.442717328727692e-05,
      "loss": 0.0066,
      "step": 1140
    },
    {
      "epoch": 1.987248757294143,
      "grad_norm": 0.05549589917063713,
      "learning_rate": 3.3851468048359244e-05,
      "loss": 0.0043,
      "step": 1150
    },
    {
      "epoch": 2.0034579641236223,
      "grad_norm": 0.5320270657539368,
      "learning_rate": 3.327576280944157e-05,
      "loss": 0.0074,
      "step": 1160
    },
    {
      "epoch": 2.0207477847417334,
      "grad_norm": 0.09530900418758392,
      "learning_rate": 3.27000575705239e-05,
      "loss": 0.0011,
      "step": 1170
    },
    {
      "epoch": 2.0380376053598446,
      "grad_norm": 0.04256858676671982,
      "learning_rate": 3.212435233160622e-05,
      "loss": 0.001,
      "step": 1180
    },
    {
      "epoch": 2.0553274259779553,
      "grad_norm": 0.02406337484717369,
      "learning_rate": 3.1548647092688545e-05,
      "loss": 0.0069,
      "step": 1190
    },
    {
      "epoch": 2.0726172465960664,
      "grad_norm": 0.043891098350286484,
      "learning_rate": 3.097294185377087e-05,
      "loss": 0.0025,
      "step": 1200
    },
    {
      "epoch": 2.0726172465960664,
      "eval_loss": 0.009143976494669914,
      "eval_runtime": 232.9058,
      "eval_samples_per_second": 13.387,
      "eval_steps_per_second": 1.674,
      "step": 1200
    }
  ],
  "logging_steps": 10,
  "max_steps": 1737,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.427749051083223e+17,
  "train_batch_size": 5,
  "trial_name": null,
  "trial_params": null
}
